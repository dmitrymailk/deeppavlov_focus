{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List, TypedDict\n",
    "\n",
    "from core.dataloaders.focus.focus_dataloader import FoCusTestDatasetV1\n",
    "import torch\n",
    "\n",
    "test_dataset = FoCusTestDatasetV1(\n",
    "    input_dataset_path=\"./datasets/FoCus/test_focus_public.json\"\n",
    ")\n",
    "\n",
    "class FocusKnowledgeKandidateExtractorDictV1(TypedDict):\n",
    "    predicted_index: int\n",
    "    predicted_knowledge: str\n",
    "\n",
    "class FocusKnowledgeKandidateExtractorV1:\n",
    "    def __init__(self,\n",
    "        model_name: str = 'all-mpnet-base-v2'\n",
    "    ) -> None:\n",
    "        self.model_name = model_name\n",
    "        self.model: SentenceTransformer = SentenceTransformer(model_name)\n",
    "    \n",
    "    def extract(self, \n",
    "        persona: List[str],\n",
    "        query: str,\n",
    "        knowledge_candidates: List[str],\n",
    "    ) -> FocusKnowledgeKandidateExtractorDictV1:\n",
    "        persona = \" \".join(persona)\n",
    "        query = query + \" \" + persona\n",
    "\n",
    "        query_emb = self.model.encode([query], convert_to_tensor=True)\n",
    "        corpus_emb = self.model.encode(knowledge_candidates, convert_to_tensor=True)\n",
    "\n",
    "        cosine_scores = util.cos_sim(corpus_emb, query_emb)\n",
    "        top_indices = cosine_scores.topk(1, dim=0).indices.flatten().tolist()\n",
    "        top_sentences = [knowledge_candidates[i] for i in top_indices]\n",
    "        return FocusKnowledgeKandidateExtractorDictV1(\n",
    "            predicted_index=top_indices[0],\n",
    "            predicted_knowledge=top_sentences[0]\n",
    "        )\n",
    "\n",
    "\n",
    "from core.base_models.debertav3_models import DebertaV3PersonaClassificationV3\n",
    "from transformers import DebertaV2Config\n",
    "from core.hyperparameters.debertav3_hyperparameters import DebertaV3HyperparametersV1\n",
    "from core.dataloaders.focus.models.debertav3_dataloaders import DebertaV3FoCusPersonaTestDatasetSampleV1, DebertaV3FoCusPersonaTestDatasetSampleDictV2\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class FocusPersonaExtractorDictV1(TypedDict):\n",
    "    predicted_persona: List[str]\n",
    "    predicted_persona_grounding: List[int]\n",
    "\n",
    "class FocusPersonaExtractorV1:\n",
    "    def __init__(self,\n",
    "        model_name: str = 'microsoft/deberta-base',\n",
    "        sample_class = DebertaV3FoCusPersonaTestDatasetSampleDictV2,\n",
    "        model_sample_class = DebertaV3FoCusPersonaTestDatasetSampleV1\n",
    "    ) -> None:\n",
    "        self.model_name = model_name\n",
    "        self.model = DebertaV3PersonaClassificationV3.from_pretrained(\n",
    "            model_name,\n",
    "            config=DebertaV2Config.from_pretrained(\n",
    "                model_name,\n",
    "            ),\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "        self.hyperparameters = DebertaV3HyperparametersV1(\n",
    "            train_batch_size=16,\n",
    "            valid_batch_size=16,\n",
    "            max_dialog_history_tokens=70,\n",
    "            max_knowledge_candidates_tokens=220,\n",
    "            max_persona_tokens=20,\n",
    "            model_name=model_name,\n",
    "            project_name=\"focus_persona_classification\",\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.sample_class = sample_class\n",
    "        self.model_sample_class = model_sample_class\n",
    "\n",
    "    \n",
    "    def extract(self,\n",
    "        persona_sentences: List[str],\n",
    "        used_knowledge: str,\n",
    "        query: str,\n",
    "    ) -> List[str]:\n",
    "        model_persona_samples = []\n",
    "        for persona_sentence in persona_sentences:\n",
    "            sample = self.sample_class(\n",
    "                persona_sentence=persona_sentence,\n",
    "                used_knowledge=used_knowledge,\n",
    "                query=query,\n",
    "            )\n",
    "            model_persona_sample = self.model_sample_class(\n",
    "                dataset_sample=sample,\n",
    "                tokenizer=self.tokenizer,\n",
    "                h_params=self.hyperparameters,\n",
    "            )\n",
    "            model_persona_samples.append(model_persona_sample.get_dict())\n",
    "        \n",
    "        predictions = []\n",
    "        persona_preds: List[str] = []\n",
    "\n",
    "        for i, model_persona_sample in enumerate(model_persona_samples):\n",
    "            for key in model_persona_sample.keys():\n",
    "                model_persona_sample[key] = torch.tensor(model_persona_sample[key])\n",
    "                model_persona_sample[key] = model_persona_sample[key].unsqueeze(0)\n",
    "\n",
    "            outputs = self.model(\n",
    "                **model_persona_sample,\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            pred = logits.argmax(dim=1).item()\n",
    "            if pred == 1:\n",
    "                persona = persona_sentences[i]\n",
    "                persona_preds.append(persona)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        return FocusPersonaExtractorDictV1(\n",
    "            predicted_persona=persona_preds,\n",
    "            predicted_persona_grounding=predictions\n",
    "        )\n",
    "\n",
    "\n",
    "class BartFocusTestDatasetDictV1(TypedDict):\n",
    "    \"\"\"\n",
    "    knowledge: List[str] все знания об объекте из википедии что у нас есть\n",
    "    query: str последний вопрос от пользователя\n",
    "    dialog_id: str идентификатор диалога\n",
    "    predicted_persona_grouding: List[int] предсказанная персона. массив из 5 элементов, \n",
    "        где 1 - персона использована, 0 - не использована\n",
    "    predicted_persona: List[str] предсказанная персона(только использованные)\n",
    "    predicted_knowledge_index: int предсказанное знание\n",
    "    predicted_knowledge: str предсказанное знание\n",
    "    position: int позиция в диалоге\n",
    "    \"\"\"\n",
    "    knowledge: List[str]\n",
    "    query: str\n",
    "    dialog_id: str\n",
    "    predicted_persona_grouding: List[int]\n",
    "    predicted_persona: List[str]\n",
    "    predicted_knowledge_index: int\n",
    "    predicted_knowledge: str\n",
    "    position: int\n",
    "    \n",
    "\n",
    "class BartFocusTestDatasetV1:\n",
    "    def __init__(self,\n",
    "        initial_dataset: FoCusTestDatasetV1,\n",
    "        knowledge_kandidate_extractor: FocusKnowledgeKandidateExtractorV1,\n",
    "        focus_persona_extractor: FocusPersonaExtractorV1,\n",
    "    ) -> None:\n",
    "        self.initial_dataset = initial_dataset\n",
    "        self.knowledge_extractor = knowledge_kandidate_extractor\n",
    "        self.persona_extractor = focus_persona_extractor\n",
    "        self.dataset: List[BartFocusTestDatasetDictV1] = []\n",
    "\n",
    "        self.dataset = self.__build_dataset()\n",
    "    \n",
    "    def __build_dataset(self) -> List[BartFocusTestDatasetDictV1]:\n",
    "        dataset = []\n",
    "\n",
    "        for i, sample in enumerate(self.initial_dataset):\n",
    "            persona = sample[\"persona\"]\n",
    "            query = sample[\"query\"]\n",
    "            knowledge = sample[\"knowledge\"]\n",
    "            position = sample[\"position\"]\n",
    "            knowledge_candidates = sample[\"knowledge_candidate\"]\n",
    "            knowledge_prediction = self.knowledge_extractor.extract(\n",
    "                persona=persona,\n",
    "                query=query,\n",
    "                knowledge_candidates=knowledge_candidates,\n",
    "            )\n",
    "            predicted_knowledge_index = knowledge_prediction[\"predicted_index\"]\n",
    "            predicted_knowledge = knowledge_prediction[\"predicted_knowledge\"]\n",
    "\n",
    "            persona_prediction = self.persona_extractor.extract(\n",
    "                persona_sentences=persona,\n",
    "                used_knowledge=predicted_knowledge,\n",
    "                query=query,\n",
    "            )\n",
    "\n",
    "            predicted_persona_grounding = persona_prediction[\"predicted_persona_grounding\"]\n",
    "            predicted_persona = persona_prediction[\"predicted_persona\"]\n",
    "\n",
    "            dataset_sample = BartFocusTestDatasetDictV1(\n",
    "                knowledge=knowledge,\n",
    "                query=query,\n",
    "                dialog_id=sample[\"dialog_id\"],\n",
    "                predicted_persona_grouding=predicted_persona_grounding,\n",
    "                predicted_persona=predicted_persona,\n",
    "                predicted_knowledge_index=predicted_knowledge_index,\n",
    "                predicted_knowledge=predicted_knowledge,\n",
    "                position=position,\n",
    "            )\n",
    "            dataset.append(dataset_sample)\n",
    "\n",
    "        return dataset\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index: int) -> BartFocusTestDatasetDictV1:\n",
    "        return self.dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 2 rooms in this house. I know you like to play video games, so this may be a good place for you to visit.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.base_models.bart_models import BartLMV7\n",
    "from core.dataloaders.focus.models.bart_dataloaders import BartRensponseTestDatasetDictV1\n",
    "from core.dataloaders.focus.models.bart_dataloaders import BartFoCusTestDatasetSampleV1\n",
    "from core.hyperparameters.bart_hyperparameters import BartHyperparametersV3\n",
    "from core.tokenizers.bart_tokenizers import BartFoCusTokenizerV2\n",
    "from transformers import BartConfig\n",
    "import torch\n",
    "\n",
    "class ResponseGeneratorV1:\n",
    "    def __init__(self,\n",
    "    # ЭТО ВЕСА ДЛЯ LIGHTING АЛО\n",
    "        model_name: str = \"./bart_base_2cx77pua\",\n",
    "    ) -> None:\n",
    "\n",
    "        self.hyperparameters = BartHyperparametersV3(\n",
    "            model_name=model_name,\n",
    "        )\n",
    "\n",
    "        self.tokenizer = BartFoCusTokenizerV2.from_pretrained(\n",
    "            self.hyperparameters.model_name,\n",
    "            hyperparameters=self.hyperparameters,\n",
    "        )\n",
    "        self.model = BartLMV7.from_pretrained(\n",
    "            model_name, \n",
    "            config=BartConfig.from_pretrained(\n",
    "            self.hyperparameters.model_name,\n",
    "            ),  # type: ignore\n",
    "            hyperparameters=self.hyperparameters,\n",
    "            tokenizer=self.tokenizer, \n",
    "        )\n",
    "        self.model.eval()\n",
    "    \n",
    "    def generate_response(self, \n",
    "        sample: BartRensponseTestDatasetDictV1\n",
    "    ) -> str:\n",
    "        sample = BartFoCusTestDatasetSampleV1(\n",
    "            focus_dataset_sample=sample,\n",
    "            tokenizer=self.tokenizer,\n",
    "            h_params=self.hyperparameters,\n",
    "        )\n",
    "        sample = sample.get_dict()\n",
    "        for key in sample:\n",
    "            sample[key] = torch.tensor(sample[key])\n",
    "            sample[key] = sample[key].unsqueeze(0)\n",
    "        \n",
    "        generated_responses = self.model.generate(\n",
    "            # **sample,\n",
    "            input_ids=sample[\"input_ids\"],\n",
    "            attention_mask=sample[\"attention_mask\"],\n",
    "            max_length=100,\n",
    "        )\n",
    "        generated_responses = self.tokenizer.batch_decode(\n",
    "            generated_responses,\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        generated_response = generated_responses[0]\n",
    "        return generated_response\n",
    "\n",
    "response_gen = ResponseGeneratorV1(\n",
    "    model_name=\"./bart_base_2cx77pua\",\n",
    ")\n",
    "\n",
    "sample = BartRensponseTestDatasetDictV1(\n",
    "    persona=[\"i like to play video games.\", \"i like to play football.\"],\n",
    "    query=\"How many rooms in this house?\",\n",
    "    knowledge_candidate=\"It's an old building. It has 2 rooms and it's in the center of the city.\",\n",
    ")\n",
    "\n",
    "response_gen.generate_response(\n",
    "    sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_persona': [], 'predicted_persona_grounding': [0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=\"./results/microsoft/deberta-v3-small/checkpoint-87000/\"\n",
    "persona_extractor = FocusPersonaExtractorV1(\n",
    "    model_name=model_name,\n",
    ")\n",
    "\n",
    "persona_extractor.extract(\n",
    "    persona_sentences=[\n",
    "        \"I am a student\", \n",
    "        \"I like ice cream\", \n",
    "        \"I like to play football\", \n",
    "        \"I am fourteen years old\",\n",
    "        \"I have an older brother\",\n",
    "    ],\n",
    "    used_knowledge=\"I work in a school\",\n",
    "    query=\"What is your job?\",\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.hyperparameters.bart_hyperparameters import BartHyperparametersV3\n",
    "from core.tokenizers.bart_tokenizers import BartFoCusTokenizerV2\n",
    "from core.base_models.bart_models import BartLMV7\n",
    "from transformers import BartConfig\n",
    "from core.lighting_models.bart_lighting import BARTLightningModelV2\n",
    "\n",
    "hyperparameters = BartHyperparametersV3()\n",
    "tokenizer = BartFoCusTokenizerV2.from_pretrained(\n",
    "    hyperparameters.model_name,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "base_model = BartLMV7(\n",
    "    config=BartConfig.from_pretrained(\n",
    "        hyperparameters.model_name,\n",
    "    ),  # type: ignore\n",
    "    hyperparameters=hyperparameters,\n",
    "    tokenizer=tokenizer,  # type: ignore\n",
    ")\n",
    "\n",
    "checkpoint_path = \"./Test/2cx77pua/checkpoints/facebook/bart-base-epoch=03-valid_loss=1.52.ckpt\"\n",
    "\n",
    "lighting_model =  BARTLightningModelV2.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tokenizer=tokenizer,  # type: ignore\n",
    "    is_training=True,\n",
    "    base_model=base_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lighting_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_responses = model.generate(\n",
    "    input_ids=batch[\"input_ids\"],\n",
    "    attention_mask=batch[\"attention_mask\"],\n",
    "    max_length=100,\n",
    ")\n",
    "generated_responses = tokenizer.batch_decode(\n",
    "    generated_responses,\n",
    "    skip_special_tokens=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('d_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47eeeae5f0593d6ff7164e36f6d45daaa118b41372aa3e9757d1f066e1c76d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
